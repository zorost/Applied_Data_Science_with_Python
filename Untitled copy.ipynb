{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Eloy/Documents/Python/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Personal\\\\V2Maestros\\\\Modules\\\\Machine Learning Algorithms\\\\Advanced Methods'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-fb4754e204a7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"C:\\Personal\\V2Maestros\\Modules\\Machine Learning Algorithms\\Advanced Methods\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \"\"\"\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Personal\\\\V2Maestros\\\\Modules\\\\Machine Learning Algorithms\\\\Advanced Methods'"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "-----------------------------------------------------------------------------\n",
    "                    \n",
    "Problem Statement\n",
    "*****************\n",
    "The dataset contains diagnosis data about breast cancer patients\n",
    " and whether they are Benign (healthy) or Malignant\n",
    " (possible disease). We need to predict whether new patients \n",
    " are benign or malignant based on model built on this data.\n",
    "\n",
    "## Techniques Used\n",
    "\n",
    "1. Principal Component Analysis\n",
    "2. Training and Testing\n",
    "3. Confusion Matrix\n",
    "4. Bagging\n",
    "5. Boosting\n",
    "\n",
    "\n",
    "-----------------------------------------------------------------------------\n",
    "\"\"\"\n",
    "\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import sklearn.metrics\n",
    "\n",
    "os.chdir(\"C:\\Personal\\V2Maestros\\Modules\\Machine Learning Algorithms\\Advanced Methods\")\n",
    "\n",
    "\"\"\"\n",
    "Data Engineering and Analysis\n",
    "\"\"\"\n",
    "#Load the dataset\n",
    "\n",
    "cancer_data = pd.read_csv(\"breast_cancer.csv\")\n",
    "cancer_data.dtypes\n",
    "cancer_data.head()\n",
    "\n",
    "\"\"\"\n",
    "Principal Component Analysis\n",
    "\n",
    "In this section, we first scale the data and discover the\n",
    " principal components of the data. Then we only pick the \n",
    " top components that have the heaviest influence on the \n",
    " target.\n",
    " \n",
    "\"\"\"\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "predictors = cancer_data.iloc[0:,2:]\n",
    "targets = cancer_data.diagnosis\n",
    "\n",
    "#Do PCA\n",
    "pca=PCA(n_components=4)\n",
    "reduced_predictors=pca.fit_transform(predictors)\n",
    "reduced_predictors\n",
    "\n",
    "#Convert target to integer\n",
    "targets[targets == 'B']=0\n",
    "targets[targets == 'M']=1\n",
    "targets=targets.astype('int64')\n",
    "\n",
    "#Correlations\n",
    "DataFrame(reduced_predictors).join(targets).corr()\n",
    "\n",
    "#Split as training and testing\n",
    "pred_train, pred_test, tar_train, tar_test  =   train_test_split(DataFrame(reduced_predictors), targets, test_size=.3)\n",
    "\n",
    "pred_train.shape\n",
    "pred_test.shape\n",
    "tar_train.shape\n",
    "tar_test.shape\n",
    "\n",
    "#Build model on training data\n",
    "\n",
    "#Using support vector machines\n",
    "from sklearn import ensemble\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#classifier=ensemble.BaggingClassifier(DecisionTreeClassifier())\n",
    "classifier=ensemble.AdaBoostClassifier(DecisionTreeClassifier())\n",
    "\n",
    "\n",
    "classifier=classifier.fit(pred_train,tar_train)\n",
    "\n",
    "predictions=classifier.predict(pred_test)\n",
    "\n",
    "sklearn.metrics.confusion_matrix(tar_test,predictions)\n",
    "sklearn.metrics.accuracy_score(tar_test, predictions)\n",
    "sklearn.metrics.classification_report(tar_test, predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
